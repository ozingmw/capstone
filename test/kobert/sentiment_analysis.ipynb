{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JH\\miniconda3\\envs\\test\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "from kobert_tokenizer import KoBERTTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1', sp_model_kwargs={'nbest_size': -1, 'alpha': 0.6, 'enable_sampling': True})\n",
    "model = BertModel.from_pretrained('skt/kobert-base-v1', low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"한국어 모델을 공유합니다.\"\n",
    "inputs = tokenizer.batch_encode_plus([text])\n",
    "out = model(input_ids = torch.tensor(inputs['input_ids']), attention_mask = torch.tensor(inputs['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1554, -0.0150,  0.3673,  ..., -0.0094,  0.1067,  0.0844],\n",
       "         [ 0.1229, -0.3236, -0.0669,  ..., -0.4487, -0.1753, -0.2302],\n",
       "         [ 0.1008, -0.3885, -0.1219,  ..., -0.2129, -0.0330, -0.1708],\n",
       "         ...,\n",
       "         [-0.0700,  0.1174, -0.1385,  ..., -0.0272,  0.5141, -0.0093],\n",
       "         [-0.0605, -0.2776,  0.4285,  ..., -0.2879,  0.5493,  0.0797],\n",
       "         [-0.1537, -0.1819, -0.1994,  ..., -0.2862,  0.0133,  0.0783]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.5197e-02,  1.2526e-02, -2.0906e-02, -4.9571e-02, -9.7731e-01,\n",
       "          9.9156e-01, -6.7530e-01,  5.5347e-02,  2.3231e-02,  4.5100e-03,\n",
       "         -5.1811e-01, -3.6802e-02, -4.0091e-02, -7.1836e-02, -2.3317e-02,\n",
       "          8.3534e-01, -9.9642e-01,  5.2746e-02,  2.5372e-03, -8.5501e-02,\n",
       "          1.1586e-01, -4.6591e-02, -2.1023e-02,  5.6610e-01,  3.4027e-02,\n",
       "          7.5981e-01, -9.3067e-01, -6.7136e-02, -9.6185e-01, -1.7121e-01,\n",
       "          9.5807e-01,  5.7800e-01, -1.9472e-02, -4.1815e-02, -9.3780e-01,\n",
       "          4.9916e-02, -5.7409e-03, -2.2728e-02, -9.9425e-01, -6.9237e-02,\n",
       "          6.8465e-04,  3.4909e-02, -6.2844e-03,  9.9442e-01, -9.9899e-01,\n",
       "          4.0310e-02, -5.3533e-01, -2.2571e-02, -9.9929e-01,  9.8811e-01,\n",
       "         -1.2751e-01, -9.9998e-01, -9.9651e-01,  5.4741e-03, -3.5815e-02,\n",
       "         -8.2744e-01,  3.8543e-02,  8.0260e-01,  2.5858e-02, -3.3279e-02,\n",
       "          3.3252e-02, -1.3364e-02,  9.6320e-01, -9.9580e-01,  2.3712e-02,\n",
       "         -9.8593e-03, -2.1819e-02,  5.7131e-02,  1.9689e-02, -3.2284e-02,\n",
       "          9.7799e-01, -9.0611e-02,  1.7279e-01, -3.2946e-02, -5.7409e-01,\n",
       "          5.7570e-05,  3.2987e-02, -2.1082e-02,  1.1405e-01, -7.1177e-02,\n",
       "          2.7412e-02, -9.9241e-01, -6.7661e-01,  2.8413e-01,  2.0272e-03,\n",
       "         -3.9799e-02,  1.1175e-01, -6.5503e-02,  9.9622e-01, -8.3378e-01,\n",
       "          4.3311e-02, -2.6061e-02, -3.0420e-02,  4.8004e-02, -9.8523e-01,\n",
       "         -4.1778e-03,  1.7801e-02, -5.3233e-02,  1.1994e-02,  8.4690e-01,\n",
       "          3.1512e-03, -9.9731e-03,  1.0782e-02, -7.0631e-03, -9.6009e-01,\n",
       "         -5.2606e-02, -3.7219e-03, -3.6499e-02, -1.3428e-03,  9.6022e-03,\n",
       "          1.2540e-02, -4.1232e-02,  9.6691e-01,  1.4780e-02,  2.9359e-01,\n",
       "         -1.1180e-02, -2.6618e-03, -4.7588e-03,  3.1942e-02,  3.5106e-02,\n",
       "          8.3404e-02, -6.5394e-02, -9.9862e-01,  9.5117e-01, -9.9999e-01,\n",
       "          1.0240e-03, -8.7128e-01, -7.1489e-02, -3.0124e-02, -9.1398e-02,\n",
       "         -1.1825e-02,  2.4025e-02,  1.5446e-02,  8.2456e-02, -1.4861e-02,\n",
       "         -5.0143e-02, -8.9484e-01,  5.6975e-03,  4.4965e-02, -5.3344e-02,\n",
       "         -3.0324e-03,  6.7165e-02,  1.0825e-01,  8.2401e-01, -1.8425e-02,\n",
       "          6.7906e-02,  3.0822e-02,  2.8489e-02,  3.5309e-02,  1.5438e-02,\n",
       "         -9.8715e-01, -6.0994e-02, -9.1701e-01, -3.8465e-02,  1.2546e-02,\n",
       "          5.3762e-02,  3.0931e-02, -7.0556e-03,  1.4816e-03, -9.4359e-01,\n",
       "          1.0758e-02,  5.6370e-02,  3.6725e-02,  9.9708e-01,  3.1692e-02,\n",
       "          1.1596e-03, -1.4543e-02,  4.3772e-01, -2.6825e-02, -4.5654e-02,\n",
       "         -5.8781e-02, -5.8295e-02, -9.9117e-01, -6.8371e-01,  7.8358e-02,\n",
       "          9.9997e-01,  2.8381e-02, -9.5989e-01, -2.5404e-03, -3.2165e-02,\n",
       "          9.8768e-02,  9.9097e-01,  8.6352e-02, -9.9999e-01,  7.0322e-03,\n",
       "         -1.0353e-02,  6.1644e-02, -1.5536e-02,  5.6378e-02,  4.5823e-01,\n",
       "         -3.2974e-02, -9.2150e-03, -8.3104e-01, -1.9364e-02,  7.2397e-03,\n",
       "         -1.2476e-02,  2.1621e-01, -1.8090e-03, -3.4680e-02,  1.2223e-02,\n",
       "         -2.0087e-02,  6.7524e-01,  2.7462e-02, -1.7319e-02,  9.6150e-01,\n",
       "          4.1261e-03, -8.5152e-02,  3.8312e-02, -5.9093e-01,  9.5981e-01,\n",
       "          7.2527e-03,  3.1034e-02,  9.5110e-01,  9.1042e-01,  1.1993e-01,\n",
       "          2.7887e-03, -1.5895e-02,  9.7395e-01,  9.4464e-01, -9.9836e-01,\n",
       "         -9.5188e-01,  1.6848e-02,  4.1662e-03,  4.0426e-02, -4.4813e-03,\n",
       "         -3.1519e-02,  9.8529e-01, -9.9806e-01, -2.1533e-02, -7.7940e-02,\n",
       "         -9.9560e-01, -2.1870e-04,  5.3600e-03, -2.5698e-01,  2.7291e-01,\n",
       "         -2.3914e-01,  5.3425e-01,  3.9196e-03,  3.2111e-03, -1.2114e-02,\n",
       "          9.3507e-01, -2.4086e-02,  9.3231e-01, -3.6020e-02,  7.5740e-01,\n",
       "          3.5909e-02, -2.5440e-02,  9.9753e-01,  1.2859e-01,  9.9417e-01,\n",
       "         -1.8082e-02, -3.7022e-02,  1.0731e-02, -9.5281e-03, -6.0838e-02,\n",
       "         -7.9809e-02,  9.9791e-01, -1.8525e-03,  9.9517e-01, -9.5933e-01,\n",
       "          5.3300e-02,  5.2023e-02,  6.4621e-03, -1.2403e-02,  2.6209e-01,\n",
       "          4.0104e-02, -2.9280e-03, -5.7839e-01, -9.6004e-01,  2.9432e-02,\n",
       "          5.6997e-02, -5.3312e-02,  4.8074e-03,  1.6104e-01,  8.4931e-01,\n",
       "         -9.4791e-01,  2.0395e-02, -9.2236e-03, -1.9254e-03,  3.9376e-02,\n",
       "          1.7074e-02,  4.0027e-01, -9.8209e-01,  3.5404e-02,  2.1781e-03,\n",
       "         -7.7998e-03, -1.7152e-02, -9.3239e-02,  2.0302e-02,  2.3005e-02,\n",
       "          9.8101e-01, -3.3570e-02,  7.5093e-01, -3.5337e-02,  2.1599e-02,\n",
       "         -5.6106e-02, -6.3388e-01,  9.9726e-01,  1.7766e-01,  3.1342e-02,\n",
       "         -5.6624e-02,  9.2133e-02, -4.1115e-02, -4.9083e-02,  9.9997e-01,\n",
       "          8.4378e-02, -6.6566e-01,  1.6984e-02,  2.1651e-02, -7.0314e-02,\n",
       "          6.4435e-02,  7.7849e-02,  5.7229e-02,  9.6834e-01,  9.9999e-01,\n",
       "         -3.0596e-02, -2.1302e-03, -3.0537e-02, -3.0714e-02,  6.3320e-02,\n",
       "         -5.1865e-02,  1.6234e-04,  3.4152e-02, -2.7721e-02, -5.6890e-02,\n",
       "         -9.9176e-02, -9.9096e-01,  2.8188e-02, -2.2623e-03, -1.5027e-02,\n",
       "         -4.5539e-02, -2.5171e-02, -9.5657e-01, -1.4087e-01, -9.6047e-01,\n",
       "         -2.2658e-02,  1.6845e-02, -9.2824e-02, -6.2046e-02,  9.5685e-01,\n",
       "          3.8434e-02,  2.0035e-02,  8.2179e-01, -8.4108e-03, -9.8684e-01,\n",
       "         -9.9978e-01,  8.8909e-03,  8.5371e-01, -5.6934e-02,  5.8383e-02,\n",
       "         -9.9471e-02, -8.8987e-02, -2.9000e-01,  4.4525e-02, -4.8241e-02,\n",
       "         -5.0009e-03, -7.3095e-01,  9.9998e-01,  9.2480e-03,  1.7111e-02,\n",
       "          1.9901e-02,  5.9194e-02, -5.7849e-01, -9.9301e-01,  2.2823e-02,\n",
       "         -1.4390e-02, -9.9871e-01, -5.9327e-04,  3.1265e-02,  2.1786e-03,\n",
       "         -9.3780e-01,  5.1153e-03, -5.8728e-02, -4.1728e-02,  1.2126e-01,\n",
       "          4.8315e-02, -9.2558e-01,  4.7209e-01, -1.3779e-02, -6.0364e-03,\n",
       "         -9.9998e-01,  5.7254e-03,  9.7654e-01, -5.1508e-02,  1.5155e-02,\n",
       "          4.1717e-02, -2.8035e-02, -9.1637e-03,  3.5195e-03, -6.1745e-02,\n",
       "         -9.5536e-01,  9.9996e-01, -3.6490e-01, -2.3475e-01,  7.5842e-02,\n",
       "         -1.7307e-01,  5.8301e-02, -9.4847e-03,  1.3548e-02,  1.9693e-02,\n",
       "         -9.4165e-03, -8.7348e-02,  1.1062e-01,  9.4669e-01, -7.8667e-01,\n",
       "          9.8472e-01,  6.9208e-02, -6.6395e-02, -4.1203e-01, -2.8216e-02,\n",
       "          1.8331e-02, -9.9501e-01, -9.6914e-01, -3.6959e-02, -2.0501e-02,\n",
       "         -5.5200e-01, -9.6724e-03, -3.2003e-02, -5.2948e-02, -3.2587e-02,\n",
       "         -3.5871e-02, -5.7683e-01, -1.7644e-03, -9.2759e-01,  8.5869e-01,\n",
       "         -3.4394e-02,  2.0066e-02, -5.8168e-01,  8.4513e-02, -6.3545e-02,\n",
       "         -4.9388e-01, -2.0328e-02, -5.5759e-01, -6.8314e-01, -3.4532e-01,\n",
       "         -5.0017e-02,  9.3841e-01, -2.8326e-01,  8.4987e-01,  9.3719e-01,\n",
       "          6.3603e-01,  1.9852e-03, -3.3372e-02,  9.9999e-01, -7.0330e-01,\n",
       "          4.8064e-02,  5.7000e-02,  6.3821e-01,  8.9572e-01, -1.8793e-02,\n",
       "         -9.5766e-01,  7.3250e-03, -9.7303e-01,  5.7000e-02, -4.8620e-02,\n",
       "          4.8304e-01,  3.9378e-02, -3.8751e-01,  1.3294e-03,  8.2993e-01,\n",
       "          2.3834e-02, -4.2979e-03, -4.3612e-02,  2.3217e-02, -1.9303e-02,\n",
       "          9.6390e-01,  2.4040e-02, -9.4583e-01, -9.4279e-02, -9.8666e-01,\n",
       "          2.4492e-02,  6.3367e-02,  7.4933e-03,  5.4627e-01, -1.5068e-03,\n",
       "         -4.0153e-01, -4.0158e-03, -4.0067e-02,  8.2598e-01,  9.4181e-02,\n",
       "         -9.9998e-01, -9.8626e-01, -9.3065e-01,  3.3450e-03,  2.6259e-01,\n",
       "         -9.8344e-01,  8.9739e-02,  7.5558e-02, -1.1075e-01, -9.9954e-01,\n",
       "         -5.7097e-02,  5.7236e-02, -5.3608e-02,  1.0742e-01, -9.3713e-01,\n",
       "         -7.5513e-03,  4.3232e-01, -2.4342e-03,  3.1716e-03, -1.4683e-01,\n",
       "         -9.9099e-01,  1.3144e-02, -3.1915e-02, -5.2123e-01, -2.4655e-02,\n",
       "          4.2343e-01,  2.3707e-01, -8.4742e-01,  9.9224e-01, -4.3127e-02,\n",
       "         -7.2845e-02, -4.3132e-01,  9.7068e-02,  7.9618e-03, -7.9714e-01,\n",
       "          9.2455e-01,  6.5169e-02, -1.9123e-02, -5.2973e-02, -9.3342e-02,\n",
       "         -3.4624e-02,  8.1650e-02, -1.8784e-02, -8.0761e-01, -7.1122e-03,\n",
       "          8.5199e-01,  5.0713e-02,  3.3217e-04,  6.9106e-02,  4.2433e-02,\n",
       "         -9.8644e-01,  3.3139e-03, -9.9184e-01, -2.9564e-02,  8.9984e-01,\n",
       "          7.2060e-01, -7.9699e-02,  1.2134e-02,  1.0020e-03, -9.9989e-01,\n",
       "         -2.9645e-03, -1.0000e+00,  7.8761e-02,  6.1437e-01, -3.4938e-02,\n",
       "         -2.3349e-02,  2.1533e-02,  1.8100e-02, -8.7273e-01, -9.2702e-01,\n",
       "         -4.7151e-02, -9.9999e-01, -9.8995e-01, -8.0021e-01, -9.4308e-02,\n",
       "          2.3066e-01,  4.6256e-02,  5.7805e-01, -1.8897e-02, -3.0696e-02,\n",
       "         -5.0692e-01, -6.9982e-02,  4.6907e-02,  3.9684e-02, -9.4130e-01,\n",
       "         -4.4868e-02,  2.5180e-02, -2.5698e-02,  2.3237e-02, -5.0230e-01,\n",
       "          7.0391e-03, -4.7195e-02,  2.6988e-02, -9.9311e-01,  2.9732e-02,\n",
       "          1.0654e-02,  3.9880e-02,  2.5688e-01, -7.8164e-02,  3.3404e-03,\n",
       "          6.0766e-02, -9.6415e-01,  2.8375e-04, -3.7492e-02,  8.8840e-01,\n",
       "         -9.1815e-03, -3.4286e-03, -9.6691e-01, -3.5383e-02,  7.5131e-01,\n",
       "          6.9293e-01,  6.9224e-01,  9.9303e-01,  7.8836e-02,  6.4091e-01,\n",
       "         -7.7385e-03, -4.3151e-01,  8.0024e-02,  9.5829e-01, -2.8434e-02,\n",
       "          1.5490e-03,  2.0705e-02, -9.8741e-01,  5.4546e-02, -9.9990e-01,\n",
       "          5.8355e-02, -9.8138e-01, -9.8336e-01, -1.3430e-03,  2.0571e-02,\n",
       "         -8.8442e-01, -7.1332e-01,  2.6191e-02, -1.8135e-02,  5.9189e-03,\n",
       "          1.6197e-02,  7.1328e-03, -9.5013e-01, -1.3307e-02,  5.8956e-01,\n",
       "         -1.3087e-02, -1.3999e-02,  4.2700e-02, -6.2579e-02, -2.7303e-02,\n",
       "          9.4154e-03, -1.4349e-02,  9.6016e-01,  4.4394e-01, -9.5806e-01,\n",
       "          8.1432e-01, -9.9054e-03, -9.5997e-01, -4.9584e-02,  3.1852e-02,\n",
       "         -5.6344e-03,  9.7473e-01,  3.0388e-02,  1.0000e+00,  9.9039e-01,\n",
       "         -9.6436e-01,  6.2123e-01,  1.2589e-03,  6.3712e-01, -5.6715e-02,\n",
       "         -9.5321e-01, -5.4790e-02, -9.4971e-01, -4.0235e-02,  6.9230e-03,\n",
       "          4.2838e-02, -3.1996e-01, -9.9841e-01,  2.5414e-02, -2.3247e-02,\n",
       "         -1.0253e-01, -9.1436e-01, -2.9565e-02, -9.9994e-01,  2.1628e-02,\n",
       "          9.8026e-01,  9.2917e-01, -3.8465e-02, -1.7672e-02,  9.9858e-01,\n",
       "          9.0906e-01, -9.3093e-01,  5.4479e-03,  3.8040e-02,  1.1974e-02,\n",
       "         -9.8447e-01, -1.9743e-02, -3.3284e-01, -4.8346e-04,  7.2251e-02,\n",
       "          1.2176e-02,  1.0974e-02,  5.4018e-01, -1.2867e-01, -5.4206e-02,\n",
       "          5.7444e-03,  9.0365e-01,  1.2500e-02, -9.6540e-02,  3.5239e-02,\n",
       "         -7.0963e-01,  5.5002e-02,  9.9998e-01,  8.4911e-01,  9.4085e-01,\n",
       "          9.9761e-01, -6.3108e-03, -4.0790e-02,  9.3981e-01,  6.3795e-01,\n",
       "          3.6250e-02, -7.2845e-02, -9.9647e-01, -1.8132e-02,  2.9783e-01,\n",
       "          9.6961e-01,  3.8222e-01, -9.9998e-01,  8.3315e-03,  9.8380e-01,\n",
       "          9.7967e-01, -6.5250e-01,  9.3331e-01, -9.8891e-01, -6.1939e-01,\n",
       "          3.6034e-02,  1.4953e-01, -7.4738e-01, -5.3545e-02,  4.3884e-02,\n",
       "          9.9999e-01,  1.5039e-01,  1.6797e-02,  2.6905e-02,  1.9737e-02,\n",
       "         -6.8264e-02, -4.8807e-02, -2.9707e-02,  9.4600e-01, -1.3704e-02,\n",
       "          3.7270e-03, -1.1898e-02, -9.9979e-01, -3.3232e-01, -2.0500e-01,\n",
       "         -1.3862e-02, -1.1782e-02, -9.9879e-01,  2.6497e-02, -4.6407e-02,\n",
       "         -7.0217e-04, -2.4121e-01,  2.3335e-03, -2.4632e-02,  3.5001e-01,\n",
       "         -9.9634e-03, -2.0773e-02, -1.5709e-02,  7.4071e-02,  5.5607e-02,\n",
       "          9.7022e-01, -6.7267e-01,  1.5011e-02,  1.9265e-01,  9.9499e-01,\n",
       "          1.2096e-02,  2.6780e-02, -5.0804e-01, -9.8375e-01, -9.6202e-01,\n",
       "          9.8026e-01,  3.7138e-02, -7.5123e-02, -3.8577e-02, -7.8318e-01,\n",
       "          3.1657e-01,  9.4517e-01, -7.7084e-01, -3.6669e-02, -9.9821e-01,\n",
       "          9.7941e-02, -5.3265e-03,  1.8041e-02]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>신체질환</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>감정_소분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>시스템문장1</th>\n",
       "      <th>사람문장2</th>\n",
       "      <th>시스템문장2</th>\n",
       "      <th>사람문장3</th>\n",
       "      <th>시스템문장3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "      <td>그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.</td>\n",
       "      <td>혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "      <td>최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.</td>\n",
       "      <td>월급이 줄어든 만큼 소비를 줄일 계획이군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "      <td>잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...</td>\n",
       "      <td>스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "      <td>직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.</td>\n",
       "      <td>직장 사람들과 이야기를 해 보겠다고 결심하셨군요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>청년</td>\n",
       "      <td>여성</td>\n",
       "      <td>진로,취업,직장</td>\n",
       "      <td>해당없음</td>\n",
       "      <td>분노</td>\n",
       "      <td>노여워하는</td>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "      <td>상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!</td>\n",
       "      <td>항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   연령  성별     상황키워드  신체질환 감정_대분류 감정_소분류  \\\n",
       "1  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "2  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "3  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "4  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "5  청년  여성  진로,취업,직장  해당없음     분노  노여워하는   \n",
       "\n",
       "                                               사람문장1  \\\n",
       "1                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "2     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "3  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "4  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "5              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "\n",
       "                                              시스템문장1  \\\n",
       "1                        많이 힘드시겠어요. 주위에 의논할 상대가 있나요?   \n",
       "2           급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?   \n",
       "3  회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...   \n",
       "4  관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...   \n",
       "5  무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...   \n",
       "\n",
       "                                               사람문장2  \\\n",
       "1                그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.   \n",
       "2   최대한 지출을 억제해야겠어. 월급이 줄어들었으니 고정지출을 줄일 수밖에 없을 것 같아.   \n",
       "3  잘 안 맞는 사람이랑 억지로 잘 지내는 것보단 조금은 거리를 두고 예의를 갖춰서 대...   \n",
       "4              직장 사람들과 솔직하게 이야기해보고 싶어. 일하는 데에 방해된다고.   \n",
       "5                상사인 나에게 먼저 인사하지 않아서 매일 내가 먼저 인사한다고!   \n",
       "\n",
       "                                              시스템문장2 사람문장3 시스템문장3  \n",
       "1     혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.    NaN    NaN  \n",
       "2                           월급이 줄어든 만큼 소비를 줄일 계획이군요.   NaN    NaN  \n",
       "3          스트레스받지 않기 위해선 인간관계에 있어 약간의 거리를 두는 게 좋겠군요.   NaN    NaN  \n",
       "4                        직장 사람들과 이야기를 해 보겠다고 결심하셨군요.   NaN    NaN  \n",
       "5  항상 먼저 인사하게 되어 화가 나셨군요. 어떻게 하면 신입사원에게 화났음을 표현할 ...   NaN    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "train_data = pd.read_csv(\"../../datasets/train.csv\", index_col = 0, encoding = 'utf-8')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51630 entries, 1 to 51630\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   연령      51630 non-null  object\n",
      " 1   성별      51630 non-null  object\n",
      " 2   상황키워드   51630 non-null  object\n",
      " 3   신체질환    51630 non-null  object\n",
      " 4   감정_대분류  51630 non-null  object\n",
      " 5   감정_소분류  51630 non-null  object\n",
      " 6   사람문장1   51630 non-null  object\n",
      " 7   시스템문장1  51630 non-null  object\n",
      " 8   사람문장2   51630 non-null  object\n",
      " 9   시스템문장2  51630 non-null  object\n",
      " 10  사람문장3   42695 non-null  object\n",
      " 11  시스템문장3  42695 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "상황키워드\n",
       "대인관계            10926\n",
       "진로,취업,직장         5224\n",
       "재정               4962\n",
       "건강,죽음            4222\n",
       "가족관계             4208\n",
       "연애,결혼,출산         4085\n",
       "대인관계(부부, 자녀)     3402\n",
       "학업 및 진로          3283\n",
       "학교폭력/따돌림         3091\n",
       "건강               3022\n",
       "재정,은퇴,노후준비       2738\n",
       "직장, 업무 스트레스      2467\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['상황키워드'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신체질환\n",
       "해당없음      37056\n",
       "만성질환 무     9256\n",
       "만성질환 유     5318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['신체질환'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "감정_대분류\n",
       "불안    9320\n",
       "분노    9160\n",
       "상처    9143\n",
       "슬픔    9125\n",
       "당황    8756\n",
       "기쁨    6126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['감정_대분류'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['감정_소분류'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>사람문장1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>지금까지 힘들게 일했는데 은퇴해서 돈이 없다고 하니 자식이 화를 내서 상처를 받았어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>친구한테 은퇴할 거라고 얘기했더니 앞으로 뭘 먹고 살 거냐면서 비웃더라고. 기분이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>친구한테 은퇴한다고 했더니 그게 말이나 되는 거냐며 날 한심한 사람 취급해서 서운했어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>그동안 열심히 달려와서 좀 쉬려고 하는데 은퇴한다고 하니 주변에서 다 말려서 기분이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>많은 고민 후 은퇴를 결심했는데 주변에서 다들 섣부른 생각이라고 해서 마음이 안 좋아.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>노년</td>\n",
       "      <td>남성</td>\n",
       "      <td>재정</td>\n",
       "      <td>분노</td>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>불안</td>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>상처</td>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>불안</td>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>상처</td>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42694 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       연령  성별       상황키워드 감정_대분류  \\\n",
       "305    중년  여성  재정,은퇴,노후준비     상처   \n",
       "306    중년  여성  재정,은퇴,노후준비     상처   \n",
       "307    중년  여성  재정,은퇴,노후준비     상처   \n",
       "308    중년  여성  재정,은퇴,노후준비     상처   \n",
       "309    중년  여성  재정,은퇴,노후준비     상처   \n",
       "...    ..  ..         ...    ...   \n",
       "51626  노년  남성          재정     분노   \n",
       "51627  노년  여성          재정     불안   \n",
       "51628  노년  여성          재정     상처   \n",
       "51629  노년  여성        대인관계     불안   \n",
       "51630  노년  여성        대인관계     상처   \n",
       "\n",
       "                                                   사람문장1  \n",
       "305      지금까지 힘들게 일했는데 은퇴해서 돈이 없다고 하니 자식이 화를 내서 상처를 받았어.  \n",
       "306    친구한테 은퇴할 거라고 얘기했더니 앞으로 뭘 먹고 살 거냐면서 비웃더라고. 기분이 ...  \n",
       "307     친구한테 은퇴한다고 했더니 그게 말이나 되는 거냐며 날 한심한 사람 취급해서 서운했어.  \n",
       "308    그동안 열심히 달려와서 좀 쉬려고 하는데 은퇴한다고 하니 주변에서 다 말려서 기분이...  \n",
       "309     많은 고민 후 은퇴를 결심했는데 주변에서 다들 섣부른 생각이라고 해서 마음이 안 좋아.  \n",
       "...                                                  ...  \n",
       "51626     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.  \n",
       "51627        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.  \n",
       "51628   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.  \n",
       "51629  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.  \n",
       "51630  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.  \n",
       "\n",
       "[42694 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dropna(inplace = True)\n",
    "train_data.drop(['감정_소분류','시스템문장1','시스템문장2','시스템문장3', '사람문장2', '사람문장3', '신체질환'], axis=1, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>성별</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>지금까지 힘들게 일했는데 은퇴해서 돈이 없다고 하니 자식이 화를 내서 상처를 받았어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>친구한테 은퇴할 거라고 얘기했더니 앞으로 뭘 먹고 살 거냐면서 비웃더라고. 기분이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>친구한테 은퇴한다고 했더니 그게 말이나 되는 거냐며 날 한심한 사람 취급해서 서운했어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>그동안 열심히 달려와서 좀 쉬려고 하는데 은퇴한다고 하니 주변에서 다 말려서 기분이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>중년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정,은퇴,노후준비</td>\n",
       "      <td>상처</td>\n",
       "      <td>많은 고민 후 은퇴를 결심했는데 주변에서 다들 섣부른 생각이라고 해서 마음이 안 좋아.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51626</th>\n",
       "      <td>노년</td>\n",
       "      <td>남성</td>\n",
       "      <td>재정</td>\n",
       "      <td>분노</td>\n",
       "      <td>나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51627</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>불안</td>\n",
       "      <td>몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>재정</td>\n",
       "      <td>상처</td>\n",
       "      <td>이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51629</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>불안</td>\n",
       "      <td>몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>노년</td>\n",
       "      <td>여성</td>\n",
       "      <td>대인관계</td>\n",
       "      <td>상처</td>\n",
       "      <td>남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42694 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       연령  성별       상황키워드 label  \\\n",
       "305    중년  여성  재정,은퇴,노후준비    상처   \n",
       "306    중년  여성  재정,은퇴,노후준비    상처   \n",
       "307    중년  여성  재정,은퇴,노후준비    상처   \n",
       "308    중년  여성  재정,은퇴,노후준비    상처   \n",
       "309    중년  여성  재정,은퇴,노후준비    상처   \n",
       "...    ..  ..         ...   ...   \n",
       "51626  노년  남성          재정    분노   \n",
       "51627  노년  여성          재정    불안   \n",
       "51628  노년  여성          재정    상처   \n",
       "51629  노년  여성        대인관계    불안   \n",
       "51630  노년  여성        대인관계    상처   \n",
       "\n",
       "                                                    text  \n",
       "305      지금까지 힘들게 일했는데 은퇴해서 돈이 없다고 하니 자식이 화를 내서 상처를 받았어.  \n",
       "306    친구한테 은퇴할 거라고 얘기했더니 앞으로 뭘 먹고 살 거냐면서 비웃더라고. 기분이 ...  \n",
       "307     친구한테 은퇴한다고 했더니 그게 말이나 되는 거냐며 날 한심한 사람 취급해서 서운했어.  \n",
       "308    그동안 열심히 달려와서 좀 쉬려고 하는데 은퇴한다고 하니 주변에서 다 말려서 기분이...  \n",
       "309     많은 고민 후 은퇴를 결심했는데 주변에서 다들 섣부른 생각이라고 해서 마음이 안 좋아.  \n",
       "...                                                  ...  \n",
       "51626     나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.  \n",
       "51627        몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.  \n",
       "51628   이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.  \n",
       "51629  몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.  \n",
       "51630  남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.  \n",
       "\n",
       "[42694 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.rename({'사람문장1':'text', '감정_대분류':'label'}, axis=1, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 0, 2, 3, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['상처', '슬픔', '기쁨', '분노', '불안', '당황'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([4,5,0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['text']\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305        지금까지 힘들게 일했는데 은퇴해서 돈이 없다고 하니 자식이 화를 내서 상처를 받았어.\n",
       "306      친구한테 은퇴할 거라고 얘기했더니 앞으로 뭘 먹고 살 거냐면서 비웃더라고. 기분이 ...\n",
       "307       친구한테 은퇴한다고 했더니 그게 말이나 되는 거냐며 날 한심한 사람 취급해서 서운했어.\n",
       "308      그동안 열심히 달려와서 좀 쉬려고 하는데 은퇴한다고 하니 주변에서 다 말려서 기분이...\n",
       "309       많은 고민 후 은퇴를 결심했는데 주변에서 다들 섣부른 생각이라고 해서 마음이 안 좋아.\n",
       "                               ...                        \n",
       "51626       나이가 먹고 이제 돈도 못 벌어 오니까 어떻게 살아가야 할지 막막해. 능력도 없고.\n",
       "51627          몸이 많이 약해졌나 봐. 이제 전과 같이 일하지 못할 것 같아 너무 짜증 나.\n",
       "51628     이제 어떻게 해야 할지 모르겠어. 남편도 그렇고 노후 준비도 안 되어서 미래가 걱정돼.\n",
       "51629    몇십 년을 함께 살았던 남편과 이혼했어. 그동안의 세월에 배신감을 느끼고 너무 화가 나.\n",
       "51630    남편과 결혼한 지 사십 년이야. 이제 사람 만나는 것도 버겁고 알던 사람도 점점 사라져.\n",
       "Name: text, Length: 42694, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "numpy 버전이 1.20미만이면 np.bool이 없고 np.bool_만 존재하는데\n",
    "vocab을 호출하기 위해 최소 install 조건이 \n",
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "!pip install gluonnlp\n",
    "!pip install mxnet\n",
    "3가지\n",
    "\n",
    "이때 numpy 버전이 1.16버전? 으로 다운그레이드 되어버림\n",
    "따라서 mxnet/numpy/utils.py파일에서 37번째 줄\n",
    "bool = onp.bool -> bool = onp.bool_로 수정해야함\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\numpy\\utils.py:37: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.  (This may have returned Python scalars in past versions.\n",
      "  bool = onp.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\JH\\AppData\\Local\\Temp\\ipykernel_13496\\1885493699.py\", line 2, in <module>\n",
      "    from gluonnlp import nlp\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\gluonnlp\\__init__.py\", line 22, in <module>\n",
      "    import mxnet\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\__init__.py\", line 33, in <module>\n",
      "    from . import contrib\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\contrib\\__init__.py\", line 30, in <module>\n",
      "    from . import text\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\contrib\\text\\__init__.py\", line 23, in <module>\n",
      "    from . import embedding\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\contrib\\text\\embedding.py\", line 36, in <module>\n",
      "    from ... import numpy as _mx_np\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\numpy\\__init__.py\", line 23, in <module>\n",
      "    from .multiarray import *  # pylint: disable=wildcard-import\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\numpy\\multiarray.py\", line 47, in <module>\n",
      "    from .utils import _get_np_op\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\mxnet\\numpy\\utils.py\", line 37, in <module>\n",
      "    bool = onp.bool\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\numpy\\__init__.py\", line 284, in __getattr__\n",
      "AttributeError: module 'numpy' has no attribute 'bool'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\JH\\miniconda3\\envs\\capstone\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gluonnlp import nlp\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "from KoBERT.kobert.pytorch_kobert import get_kobert_model\n",
    "bertmodel, vocab = get_kobert_model('skt/kobert-base-v1',tokenizer.vocab_file)\n",
    "\n",
    "class BERTSentenceTransform:\n",
    "    r\"\"\"BERT style data transformation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer : BERTTokenizer.\n",
    "        Tokenizer for the sentences.\n",
    "    max_seq_length : int.\n",
    "        Maximum sequence length of the sentences.\n",
    "    pad : bool, default True\n",
    "        Whether to pad the sentences to maximum length.\n",
    "    pair : bool, default True\n",
    "        Whether to transform sentences or sentence pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, max_seq_length, vocab, pad=True, pair=True):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_seq_length = max_seq_length\n",
    "        self._pad = pad\n",
    "        self._pair = pair\n",
    "        self._vocab = vocab\n",
    "\n",
    "    def __call__(self, line):\n",
    "        \"\"\"Perform transformation for sequence pairs or single sequences.\n",
    "\n",
    "        The transformation is processed in the following steps:\n",
    "        - tokenize the input sequences\n",
    "        - insert [CLS], [SEP] as necessary\n",
    "        - generate type ids to indicate whether a token belongs to the first\n",
    "        sequence or the second sequence.\n",
    "        - generate valid length\n",
    "\n",
    "        For sequence pairs, the input is a tuple of 2 strings:\n",
    "        text_a, text_b.\n",
    "\n",
    "        Inputs:\n",
    "            text_a: 'is this jacksonville ?'\n",
    "            text_b: 'no it is not'\n",
    "        Tokenization:\n",
    "            text_a: 'is this jack ##son ##ville ?'\n",
    "            text_b: 'no it is not .'\n",
    "        Processed:\n",
    "            tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n",
    "            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "            valid_length: 14\n",
    "\n",
    "        For single sequences, the input is a tuple of single string:\n",
    "        text_a.\n",
    "\n",
    "        Inputs:\n",
    "            text_a: 'the dog is hairy .'\n",
    "        Tokenization:\n",
    "            text_a: 'the dog is hairy .'\n",
    "        Processed:\n",
    "            text_a: '[CLS] the dog is hairy . [SEP]'\n",
    "            type_ids: 0     0   0   0  0     0 0\n",
    "            valid_length: 7\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        line: tuple of str\n",
    "            Input strings. For sequence pairs, the input is a tuple of 2 strings:\n",
    "            (text_a, text_b). For single sequences, the input is a tuple of single\n",
    "            string: (text_a,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n",
    "        np.array: valid length in 'int32', shape (batch_size,)\n",
    "        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # convert to unicode\n",
    "        text_a = line[0]\n",
    "        if self._pair:\n",
    "            assert len(line) == 2\n",
    "            text_b = line[1]\n",
    "\n",
    "        tokens_a = self._tokenizer.tokenize(text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        if self._pair:\n",
    "            tokens_b = self._tokenizer(text_b)\n",
    "\n",
    "        if tokens_b:\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            self._truncate_seq_pair(tokens_a, tokens_b,\n",
    "                                    self._max_seq_length - 3)\n",
    "        else:\n",
    "            # Account for [CLS] and [SEP] with \"- 2\"\n",
    "            if len(tokens_a) > self._max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
    "\n",
    "        # The embedding vectors for `type=0` and `type=1` were learned during\n",
    "        # pre-training and are added to the wordpiece embedding vector\n",
    "        # (and position vector). This is not *strictly* necessary since\n",
    "        # the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        #vocab = self._tokenizer.vocab\n",
    "        vocab = self._vocab\n",
    "        tokens = []\n",
    "        tokens.append(vocab.cls_token)\n",
    "        tokens.extend(tokens_a)\n",
    "        tokens.append(vocab.sep_token)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens.extend(tokens_b)\n",
    "            tokens.append(vocab.sep_token)\n",
    "            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The valid length of sentences. Only real  tokens are attended to.\n",
    "        valid_length = len(input_ids)\n",
    "\n",
    "        if self._pad:\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = self._max_seq_length - valid_length\n",
    "            # use padding tokens for the rest\n",
    "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
    "            segment_ids.extend([0] * padding_length)\n",
    "\n",
    "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
    "            np.array(segment_ids, dtype='int32')\n",
    "    \n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "\n",
    "tok=tokenizer.tokenize\n",
    "\n",
    "data_train = BERTDataset(X_train, 0, 1, tok, vocab, max_len, True, False)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BERTClassifier.forward() got an unexpected keyword argument 'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(X_train[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Move the inputs to CUDA\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BERTClassifier.forward() got an unexpected keyword argument 'input_ids'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BERTClassifier(model, dr_rate=0.5).to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus(X_train[:10].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}  # Move the inputs to CUDA\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1000, 768], got [1000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [1000, 768], got [1000]"
     ]
    }
   ],
   "source": [
    "loss_fn(outputs.last_hidden_state, torch.tensor(y_train[:1000].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Move the inputs to CUDA\u001b[39;00m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], attention_mask\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JH\\miniconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not Series"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 50\n",
    "loss_fn = CrossEntropyLoss()\n",
    "losses = []\n",
    "\n",
    "model.to(device)  # Move the model to CUDA\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    inputs = tokenizer.batch_encode_plus(X_train[:1000].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move the inputs to CUDA\n",
    "    outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    loss = loss_fn(outputs.last_hidden_state, y_train[:1000])\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
